{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMTOOLS -- Preprocessing\n",
    "This notebook preprocesses images for prediction using a DNN trained with Uni-EM. It opens a series of image files in `path_input`, downsamples them and applies CLAHE (Contrast limited adaptive histogram equalization), which enhances the local contrast of images. It then re-saves them as RGB .png files to `path_results`. Please note you might need to adapt the downsampling factor `ds` depending on your data resolution.\n",
    "\n",
    "**Author:** Philip Ruthig, Paul Flechsig Institute, Center of Neuropathology and Brain Research Leipzig\n",
    "\n",
    "**Contact:** philip.ruthig@medizin.uni-leipzig.de // philip.ruthig@gmail.com\n",
    "\n",
    "**Publication:**\n",
    "Please contact me if you want to use this code for any publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import skimage\n",
    "import scipy.stats as stats\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from skimage.transform import downscale_local_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(image_array, batch_size, overlap):\n",
    "    img_list = []\n",
    "    yx_list = []\n",
    "\n",
    "    for i in range(0, image_array.shape[0] - batch_size + 1, batch_size - overlap):\n",
    "        for j in range(0, image_array.shape[1] - batch_size + 1, batch_size - overlap):\n",
    "            if i + batch_size > image_array.shape[0]:\n",
    "                i = image_array.shape[0] - batch_size\n",
    "            if j + batch_size > image_array.shape[1]:\n",
    "                j = image_array.shape[1] - batch_size\n",
    "\n",
    "            batch = image_array[i:i+batch_size, j:j+batch_size]\n",
    "            img_list.append(batch)\n",
    "            yx_list.append((i,i+batch_size,j,j+batch_size))\n",
    "\n",
    "    return img_list, yx_list\n",
    "\n",
    "def remove_whitespaces(string):\n",
    "    return \"\".join(string.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user inputs\n",
    "path_input = r\"0_raw\\\\\"\n",
    "path_results = r\"1_preprocessed\\\\\"\n",
    "ds = 4 # each axis of the image is downsampled by this factor.\n",
    "batch_size = 2048 # width and length of each resulting image.\n",
    "overlap = 200 # overlap of each neighbouring image batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name_list = []\n",
    "img_coord_list = []\n",
    "img_original_shape_list = []\n",
    "img_original_name_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images = [f for f in listdir(path_input) if isfile(join(path_input, f)) and f != \".gitkeep\"]\n",
    "for i1 in tqdm.tqdm(range(len(path_images))):\n",
    "    print(f\"processing {path_images[i1]}\")\n",
    "    if path_images[i1].endswith(\".tif\") or path_images[i1].endswith(\".tiff\") or path_images[i1].endswith(\".TIF\") or path_images[i1].endswith(\".TIFF\"):\n",
    "        test_img = tf.imread(path_input + str(path_images[i1])) # use this for tiff\n",
    "        if len(test_img.shape)==3: # if img is RGB\n",
    "            temp = (test_img[:,:,0]+test_img[:,:,1]+test_img[:,:,2])/3 # average RGB to grayscale\n",
    "            test_img = temp.astype('uint8')\n",
    "    elif path_images[i1].endswith(\".png\") or path_images[i1].endswith(\".PNG\"):\n",
    "        test_img = cv2.imread(path_input + str(path_images[i1]),-1) # use this for png \n",
    "        try: # average RGB to grayscale\n",
    "            test_img = (test_img[:,:,0]+test_img[:,:,1]+test_img[:,:,2])/3\n",
    "        except: # if img is grayscale already\n",
    "            print(\"\")\n",
    "        test_img = test_img.astype('uint8')\n",
    "    else:\n",
    "        print('Input file format not supported. Use .png or .tif.')\n",
    "        break\n",
    "    test_img_ds = downscale_local_mean(test_img, ds)\n",
    "    img_original_shape_list.append(test_img_ds.shape)\n",
    "    test_img_ds_pad = np.pad(test_img_ds, batch_size, mode='reflect')\n",
    "    img_list,coords = batch_generator(test_img_ds_pad, batch_size, overlap)\n",
    "    for i2 in tqdm.tqdm(range(len(img_list))):\n",
    "        test_img_clahe = skimage.exposure.equalize_adapthist(img_list[i2]/np.max(img_list[i2]),clip_limit=0.01,kernel_size=127)\n",
    "        test_img_rgb_png = cv2.merge((downscale_local_mean(test_img_clahe,1),#R\n",
    "                                    downscale_local_mean(test_img_clahe,1),  #G\n",
    "                                    downscale_local_mean(test_img_clahe,1))) #B\n",
    "        skimage.io.imsave(path_results + path_images[i1][:-4] + remove_whitespaces(str(coords[i2])) +  \".png\", (test_img_rgb_png*255).astype('uint8'))\n",
    "        img_name_list.append(path_images[i1][:-4] + remove_whitespaces(str(coords[i2])) +  \".png\")\n",
    "        img_coord_list.append(coords[i2])\n",
    "        img_original_name_list.append(path_images[i1][:-4])\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save metadata as pkl files\n",
    "with open(r\"img_name_list\",\"wb\") as fp:\n",
    "    pickle.dump(img_name_list,fp)\n",
    "\n",
    "with open(r\"img_coord_list\",\"wb\") as fp:\n",
    "    pickle.dump(img_coord_list,fp)\n",
    "\n",
    "with open(r\"img_original_shape_list\",\"wb\") as fp:\n",
    "    pickle.dump(img_original_shape_list,fp)\n",
    "\n",
    "with open(r\"img_original_name_list\",\"wb\") as fp:\n",
    "    pickle.dump(img_original_name_list,fp)\n",
    "\n",
    "with open(r\"batch_size\",\"wb\") as fp:\n",
    "    pickle.dump(batch_size,fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
