{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMTOOLS -- Preprocessing\n",
    "This notebook preprocesses images for prediction using a DNN trained with Uni-EM. It opens a series of .tiff or .png files in `path_input` and applies CLAHE (Contrast limited adaptive histogram equalization), which enhances the local contrast of images. It then re-saves them as RGB .png files to `path_results`. After using this notebook on your raw data, the images can be used for segmentation, e.g. with Uni-EM.\n",
    "\n",
    "**Author:** Philip Ruthig, Paul Flechsig Institute, Center of Neuropathology and Brain Research Leipzig\n",
    "\n",
    "**Contact:** philip.ruthig@medizin.uni-leipzig.de // philip.ruthig@gmail.com\n",
    "\n",
    "**Publication:**\n",
    "Please contact me if you want to use this code for any publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import skimage\n",
    "from skimage.transform import downscale_local_mean\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_generator(img_shape, chunk_size, overlap, resize_chunks=False):\n",
    "    y_start = 0\n",
    "    \n",
    "    while y_start < img_shape[0]:\n",
    "        y_end = y_start + chunk_size[0]\n",
    "        if y_end > img_shape[0]:\n",
    "            break\n",
    "        \n",
    "        x_start = 0\n",
    "        while x_start < img_shape[1]:\n",
    "            x_end = x_start + chunk_size[1]\n",
    "            if x_end > img_shape[1]:\n",
    "                break\n",
    "            \n",
    "            yield (y_start, y_end, x_start, x_end)\n",
    "            x_start += chunk_size[1] - overlap\n",
    "        \n",
    "        y_start += chunk_size[0] - overlap\n",
    "\n",
    "def crop_background(img, background_threshold):\n",
    "    '''\n",
    "    Returns the largest rectangular region within your 2d image that does not contain background.\n",
    "    Useful if your images contain grid shadows and you want to exclude them from your analysis.\n",
    "    '''\n",
    "    rows, cols = img.shape\n",
    "    max_area = 0\n",
    "    max_top = max_left = max_bottom = max_right = 0\n",
    "\n",
    "    # Loop through each element in the 2D array (image)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            # Check if the element meets the background threshold condition\n",
    "            if img[i, j] >= background_threshold:\n",
    "                top = bottom = i\n",
    "                left = right = j\n",
    "\n",
    "                # Expand the region vertically until the background threshold condition is not met\n",
    "                while bottom < rows and img[bottom, j] >= background_threshold:\n",
    "                    bottom += 1\n",
    "\n",
    "                # Expand the region horizontally until the background threshold condition is not met\n",
    "                while right < cols and np.all(img[i:bottom, right] >= background_threshold):\n",
    "                    right += 1\n",
    "\n",
    "                # Calculate the area of the current rectangular region\n",
    "                area = (bottom - i) * (right - j)\n",
    "\n",
    "                # Update the maximum area and the coordinates of the maximum rectangular region\n",
    "                if area > max_area:\n",
    "                    max_area = area\n",
    "                    max_top, max_left, max_bottom, max_right = i, j, bottom, right\n",
    "\n",
    "    # Return the largest rectangular region based on the maximum coordinates\n",
    "    return img[max_top:max_bottom, max_left:max_right]\n",
    "\n",
    "def remove_whitespaces(string):\n",
    "    return \"\".join(string.split())\n",
    "\n",
    "def mk_dir(directory_path):\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user inputs\n",
    "path_input = os.getcwd() + r\"\\0_raw\\\\\"\n",
    "path_results = os.getcwd() + r\"\\1_preprocessed\\\\\"\n",
    "downscale_factor = 4 # each axis of the image is downsampled with this factor.\n",
    "bg_crop = False # set to true if you want your data has black edges which you want to be cropped\n",
    "background_threshold = 100 # intensity threshold for background - if your image has dark background that you would like to crop, define a threshold for it here. Everything below that threshold is cropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:12<00:00, 12.87s/it]\n",
      "  0%|          | 0/1 [01:41<?, ?it/s].94s/it]\n",
      " 50%|█████     | 1/2 [01:55<01:55, 115.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m     coord_list\u001b[39m.\u001b[39mappend((y_start,y_end,x_start,x_end))\n\u001b[0;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m zyx \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(coord_list):\n\u001b[1;32m---> 20\u001b[0m     test_img_clahe \u001b[39m=\u001b[39m skimage\u001b[39m.\u001b[39;49mexposure\u001b[39m.\u001b[39;49mequalize_adapthist(test_img[zyx[\u001b[39m0\u001b[39;49m]:zyx[\u001b[39m1\u001b[39;49m],zyx[\u001b[39m2\u001b[39;49m]:zyx[\u001b[39m3\u001b[39;49m]],clip_limit\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m,kernel_size\u001b[39m=\u001b[39;49m\u001b[39m127\u001b[39;49m)\n\u001b[0;32m     21\u001b[0m     test_img_downscaled \u001b[39m=\u001b[39m downscale_local_mean(test_img_clahe, downscale_factor)\n\u001b[0;32m     22\u001b[0m     test_img_rgb_png \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mmerge((downscale_local_mean(test_img_downscaled,\u001b[39m1\u001b[39m),  \u001b[39m#R\u001b[39;00m\n\u001b[0;32m     23\u001b[0m                                 downscale_local_mean(test_img_downscaled,\u001b[39m1\u001b[39m),    \u001b[39m#G\u001b[39;00m\n\u001b[0;32m     24\u001b[0m                                 downscale_local_mean(test_img_downscaled,\u001b[39m1\u001b[39m)))   \u001b[39m#B\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\skimage\\color\\adapt_rgb.py:38\u001b[0m, in \u001b[0;36madapt_rgb.<locals>.decorator.<locals>.image_filter_adapted\u001b[1;34m(image, *args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(image_filter)\n\u001b[0;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimage_filter_adapted\u001b[39m(image, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     37\u001b[0m     \u001b[39mif\u001b[39;00m is_rgb_like(image):\n\u001b[1;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m apply_to_rgb(image_filter, image, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     39\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m         \u001b[39mreturn\u001b[39;00m image_filter(image, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\skimage\\color\\adapt_rgb.py:62\u001b[0m, in \u001b[0;36mhsv_value\u001b[1;34m(image_filter, image, *args, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m value \u001b[39m=\u001b[39m image_filter(value, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     61\u001b[0m hsv[:, :, \u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m _convert(value, hsv\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m color\u001b[39m.\u001b[39;49mhsv2rgb(hsv)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\skimage\\_shared\\utils.py:394\u001b[0m, in \u001b[0;36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m channel_axis \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mchannel_axis\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    393\u001b[0m \u001b[39mif\u001b[39;00m channel_axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 394\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    396\u001b[0m \u001b[39m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[39m#       supporting a tuple of channel axes. Right now, only an\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[39m#       integer or a single-element tuple is supported, though.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misscalar(channel_axis):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:371\u001b[0m, in \u001b[0;36mhsv2rgb\u001b[1;34m(hsv, channel_axis)\u001b[0m\n\u001b[0;32m    367\u001b[0m v \u001b[39m=\u001b[39m arr[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m2\u001b[39m]\n\u001b[0;32m    369\u001b[0m hi \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack([hi, hi, hi], axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8) \u001b[39m%\u001b[39m \u001b[39m6\u001b[39m\n\u001b[0;32m    370\u001b[0m out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mchoose(\n\u001b[1;32m--> 371\u001b[0m     hi, np\u001b[39m.\u001b[39;49mstack([np\u001b[39m.\u001b[39;49mstack((v, t, p), axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m    372\u001b[0m                   np\u001b[39m.\u001b[39;49mstack((q, v, p), axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m    373\u001b[0m                   np\u001b[39m.\u001b[39;49mstack((p, v, t), axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m    374\u001b[0m                   np\u001b[39m.\u001b[39;49mstack((p, q, v), axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m    375\u001b[0m                   np\u001b[39m.\u001b[39;49mstack((t, p, v), axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m    376\u001b[0m                   np\u001b[39m.\u001b[39;49mstack((v, p, q), axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)]))\n\u001b[0;32m    378\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py:433\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out)\u001b[0m\n\u001b[0;32m    431\u001b[0m sl \u001b[39m=\u001b[39m (\u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m),) \u001b[39m*\u001b[39m axis \u001b[39m+\u001b[39m (_nx\u001b[39m.\u001b[39mnewaxis,)\n\u001b[0;32m    432\u001b[0m expanded_arrays \u001b[39m=\u001b[39m [arr[sl] \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 433\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(expanded_arrays, axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mk_dir(path_results)\n",
    "path_images = [f for f in listdir(path_input) if isfile(join(path_input, f)) and f != \".gitkeep\"]\n",
    "for i in tqdm.tqdm(range(len(path_images))):\n",
    "    # print(\"Preprocessing Images \" + str(i))\n",
    "    if path_images[i].endswith(\".tif\") or path_images[i].endswith(\".tiff\") or path_images[i].endswith(\".TIF\") or path_images[i].endswith(\".TIFF\"):\n",
    "        test_img = tf.imread(path_input + str(path_images[i])) # use this for tiff\n",
    "    elif path_images[i].endswith(\".png\") or path_images[i].endswith(\".PNG\"):\n",
    "        test_img = cv2.imread(path_input + str(path_images[i]),-1) # use this for png \n",
    "    else:\n",
    "        print('Input file format not supported. Use .png or .tif.')\n",
    "        break\n",
    "    if bg_crop == True:\n",
    "        if background_threshold < test_img.min():\n",
    "            print('cropping background..')\n",
    "            test_img = crop_background(test_img,background_threshold)\n",
    "    coord_list = []\n",
    "    for y_start, y_end, x_start, x_end in chunk_generator(test_img.shape, (2048*4,2048*4),0):\n",
    "        coord_list.append((y_start,y_end,x_start,x_end))\n",
    "    for zyx in tqdm.tqdm(coord_list):\n",
    "        test_img_clahe = skimage.exposure.equalize_adapthist(test_img[zyx[0]:zyx[1],zyx[2]:zyx[3]],clip_limit=0.01,kernel_size=127)\n",
    "        test_img_downscaled = downscale_local_mean(test_img_clahe, downscale_factor)\n",
    "        test_img_rgb_png = cv2.merge((downscale_local_mean(test_img_downscaled,1),  #R\n",
    "                                    downscale_local_mean(test_img_downscaled,1),    #G\n",
    "                                    downscale_local_mean(test_img_downscaled,1)))   #B\n",
    "        skimage.io.imsave(path_results + path_images[i][:-4] + remove_whitespaces(str(zyx)) +  \".png\", (test_img_rgb_png*255).astype('uint8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
